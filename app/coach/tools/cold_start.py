from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from loguru import logger
from pydantic import SecretStr

from app.coach.models import AthleteState
from app.core.settings import settings

COLD_START_INSTRUCTIONS = """
You are Virtus Coach â€” an elite endurance training intelligence system.

This is the first time you're speaking with this athlete. Your task is to:
1. Introduce yourself warmly and professionally
2. Briefly explain your role as their AI training coach
3. Mention key capabilities (session recommendations, fatigue analysis, load adjustments, race planning)
4. If athlete state data is available, provide a brief, personalized assessment
5. Invite them to ask questions about their training

Tone:
- Warm but professional
- Confident but approachable
- Brief and focused (2-3 paragraphs max)
- No metric definitions or technical jargon

If athlete state is provided:
- Mention their current fitness, fatigue, and form state
- Provide one brief insight based on their metrics
- Keep it conversational, not clinical

Return ONLY the welcome message text. Do not include any metadata or structure.
"""

if not settings.openai_api_key:
    _cold_start_llm = None
    logger.warning("OPENAI_API_KEY is not set. Cold start LLM features will not work.")
else:
    _cold_start_llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        api_key=SecretStr(settings.openai_api_key),
    )

_cold_start_prompt = ChatPromptTemplate.from_messages([
    ("system", COLD_START_INSTRUCTIONS),
    ("human", "{context}"),
])

if _cold_start_llm is not None:
    _cold_start_chain = _cold_start_prompt | _cold_start_llm
else:
    _cold_start_chain = None


def welcome_new_user(state: AthleteState | None = None) -> str:
    """Generate a welcome message using the LLM agent for new users.

    Args:
        state: Optional athlete state. If provided, includes personalized information.

    Returns:
        A welcoming message generated by the LLM introducing the coach and its capabilities.
    """
    if _cold_start_chain is None or not settings.openai_api_key:
        logger.warning("LLM not available for cold start, using fallback message")
        fallback = (
            "Welcome! I'm your AI training coach. I'm here to help you optimize your training and performance.\n\n"
            "I can help you with training session recommendations, fatigue analysis, load adjustments, "
            "and planning your race builds. Feel free to ask me anything about your training!"
        )
        if state is not None:
            fallback += f"\n\nYour current metrics: CTL {state.ctl:.1f}, ATL {state.atl:.1f}, TSB {state.tsb:.1f}"
        return fallback

    # Build context for the LLM
    if state is not None:
        context = f"""Generate a warm welcome message for a new athlete.

Athlete's current training state:
- Fitness (CTL): {state.ctl:.1f}
- Fatigue (ATL): {state.atl:.1f}
- Form (TSB): {state.tsb:.1f}
- Load trend: {state.load_trend}
- Flags: {", ".join(state.flags) if state.flags else "none"}

Include a brief personalized insight based on these metrics."""
    else:
        context = (
            "Generate a warm welcome message for a new athlete. "
            "Training data is not yet available, so focus on introducing yourself "
            "and explaining how you can help once their data is synced."
        )

    try:
        logger.info("Generating cold start welcome message with LLM")
        response = _cold_start_chain.invoke({"context": context})
        # Chain returns AIMessage with .content attribute
        # Extract string content, handling potential list/str types
        content = response.content
        if isinstance(content, str):
            message = content
        elif isinstance(content, list):
            # If content is a list, join all string elements
            message = " ".join(str(item) for item in content if isinstance(item, str))
        else:
            message = str(content)
        logger.info("Cold start message generated successfully")
    except Exception as e:
        logger.error(f"Error generating cold start message: {e}", exc_info=True)
        # Fallback to a simple message if LLM fails
        fallback = (
            "Welcome! I'm your AI training coach. I'm here to help you optimize your training and performance.\n\n"
            "I can help you with training session recommendations, fatigue analysis, load adjustments, "
            "and planning your race builds. Feel free to ask me anything about your training!"
        )
        if state is not None:
            fallback += f"\n\nYour current metrics: CTL {state.ctl:.1f}, ATL {state.atl:.1f}, TSB {state.tsb:.1f}"
        return fallback
    else:
        return message
